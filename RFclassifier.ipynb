{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "030f4d20",
   "metadata": {},
   "source": [
    "# Random Forest for An Alignment Cost-Based Classification of Log Traces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd25f027",
   "metadata": {},
   "source": [
    "# 0. Fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60224a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import time\n",
    "\n",
    "from statistics import mean\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "#tensorflow as tf\n",
    "#from tensorflow import enable_eager_execution\n",
    "#enable_eager_execution() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45da8ef9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0447f3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness(packageForFitness, minRunLength):\n",
    "    '''\n",
    "    This function computes the fitness for all the sequences. \n",
    "    @sequences: the sequences of words\n",
    "    @costs: the real alignment cost\n",
    "    @minRunLength: the minimal run in the alignment dataset\n",
    "    '''\n",
    "    sumTraceFitness = 0\n",
    "    totTraces = 0 \n",
    "    for i in packageForFitness.index:\n",
    "        sumTraceFitness += (1 - (packageForFitness.realCosts[i] / ( packageForFitness.lengths[i]  + minRunLength )))#*packageForFitness.freqs[i]\n",
    "        #totTraces += packageForFitness.freqs[i]\n",
    "        totTraces +=1\n",
    "    return sumTraceFitness / totTraces\n",
    "\n",
    "def LB_fitness(packageForFitness, minRunLength, m_AC, indices):\n",
    "    '''\n",
    "    This function computes lower bound of the fitness given in the paper. \n",
    "    @sequences: the sequences of words\n",
    "    @minRunLength: the minimal run in the alignment dataset\n",
    "    @m_AC: needed for the lowerbound formula\n",
    "    @indices: if we compute the lower bound, then we don't iterate on all the traces but only the positives. \n",
    "    '''\n",
    "    sumTraceFitness = 0\n",
    "    totTraces = 0 \n",
    "    for i in indices:\n",
    "        sumTraceFitness += (1 - ((m_AC) / ( packageForFitness.lengths[i] + minRunLength )))#*packageForFitness.freqs[i]\n",
    "    for i in packageForFitness.index:\n",
    "        #totTraces += packageForFitness.freqs[i]\n",
    "        totTraces +=1\n",
    "    return sumTraceFitness / totTraces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e23db82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0e239c3",
   "metadata": {},
   "source": [
    "# 1. Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d82829c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the \"CountVectorizer\" object as a GLOBAL VARIABLE, which is scikit-learn's bag of words tool.\n",
    "vectorizer = CountVectorizer(analyzer = 'word',\n",
    "                            tokenizer = None,\n",
    "                            preprocessor = None,\n",
    "                            stop_words = None,\n",
    "                            max_features = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bd611ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanDataForRF(dataFile,m_AC,vectorizer_already_trained=None): \n",
    "    '''\n",
    "    Reads the file (1), specifies the target classes (2) and prepare the Bag of Words(3).\n",
    "    @dataFile: (String) filename of the alignment dataset\n",
    "    @m_AC: (int) maximal alignment cost classifier\n",
    "    '''\n",
    "    # ---- (1) yes, a bit of copy/paste... Read the file \n",
    "    data = pd.read_csv(dataFile,sep = \";\", \n",
    "                   names = [\"traces\",\"tracesWithMoves\",\"runs\",\"runsWithMoves\",\"costs\",\"frequencies\"])\n",
    "    \n",
    "    # ---- (2) create the positive and negative target depending on the m_AC parameter\n",
    "    # alignment cost which interests us is greater than 10000 (other costs are just silent moves)\n",
    "    # set the fitting to tmp_pos to set them latter to 1\n",
    "    y = ((data[\"costs\"] / 10000) / (m_AC+1)).astype(int)\n",
    "    max_y = y.max()\n",
    "    y = y.replace(0,\"tmp_pos\")\n",
    "    y = y.replace(range(1,max_y + 1), 0)\n",
    "    y = y.replace(\"tmp_pos\",1)\n",
    "    y = np.eye(2)[y.to_numpy().reshape(-1)]\n",
    "    \n",
    "    # ---- (3) prepare the Bag of Words\n",
    "    traces_to_matrix = data.traces.str.split(\":::\",expand=True,)\n",
    "    # this line takes the matrix of words, and transformed it to a list of sentences\n",
    "    data_to_fit = [' '.join( [e.replace(\" \",\"\") for e in filter(None,a)]) for a in traces_to_matrix.values.tolist()]\n",
    "    \n",
    "    if vectorizer_already_trained :\n",
    "        x = vectorizer.transform(data_to_fit).toarray()\n",
    "    else :\n",
    "        # then we can transform our data with the counter (it's like a one-hot-encode, right?)\n",
    "        x = vectorizer.fit_transform(data_to_fit).toarray()\n",
    "    \n",
    "    # for fitness computation\n",
    "    minLengthRun= len(data.runs.str.split(\":::\").min())\n",
    "    lengths = data.traces.str.split(\":::\",expand=False,).str.len()-1\n",
    "    realCosts = (data[\"costs\"] / 10000).astype(int)\n",
    "    packageForFitness = pd.DataFrame({\"lengths\":lengths, \"realCosts\": realCosts, \"freqs\": data.frequencies})\n",
    "    \n",
    "    return x, y, packageForFitness, minLengthRun, m_AC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5a5fb9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1, ..., 5, 5, 0],\n",
       "        [1, 0, 0, ..., 5, 3, 0],\n",
       "        [1, 0, 0, ..., 3, 0, 0]], dtype=int64),\n",
       " array([[0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        ...,\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of use\n",
    "x, y, packageForFitness, minLengthRun, m_AC = cleanDataForRF(\"alignments-A_2012_im.csv\",4)\n",
    "x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f0871c",
   "metadata": {},
   "source": [
    "# 3. Cross-Validation of the method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfce6224",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(forest, x_test, y_test):\n",
    "    y_test_predict_with_proba = forest.predict_proba(x_test)[1]\n",
    "    return  BinaryCrossentropy()(y_test,y_test_predict_with_proba).numpy()\n",
    "\n",
    "def acc(forest, x_test, y_test):\n",
    "    y_test_predict = forest.predict(x_test)\n",
    "    return accuracy_score(y_test,y_test_predict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41390091",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accLossPercentage(forest, x, y, indices_of_test, accArr, lossArr, percentageArr=None, freqs=None,classToTest=None):\n",
    "    '''\n",
    "    This function fills the arrays of results accArr, lossArr and percentageArr for all the test items, or only the \n",
    "    negative items (classToTest=0) or only the positive items (classToTest=1). percentageArr is optional because it \n",
    "    is not required for the entire dataset, i.e., when we do not specify the class. \n",
    "    This works by using a dynamic programmation for the arrays. The return element is either the current accuracy in \n",
    "    case of classToTest=None, either the indices in case of classToTest!=None.\n",
    "    Params:\n",
    "    @forest: a trained model\n",
    "    @x_test: the dataset to test\n",
    "    @y_test: the target value to predict for the test dataset\n",
    "    @accArr: a list of the previous accurary, or an empty list\n",
    "    @lossArr: a list of the previous loss, or an empty list\n",
    "    @percentageArr:  a list of the previous percentage, or an empty list\n",
    "    @classToTest: 1 or 0 for positive and negative. This will find the indices of the items that belongs to the class\n",
    "    '''\n",
    "    if classToTest!=None:\n",
    "        indices = [i for i in indices_of_test if y[i][1]==classToTest]\n",
    "        if len(indices)>0:\n",
    "            accArr.append(acc(forest, x[indices], y[indices]))\n",
    "            lossArr.append(loss(forest, x[indices], y[indices]))\n",
    "        #percentageArr.append(freqs[indices].sum()/freqs[indices_of_test].sum())\n",
    "        percentageArr.append(len(indices)/len(indices_of_test))\n",
    "        return indices\n",
    "    else :\n",
    "        accuracy = acc(forest, x[indices_of_test], y[indices_of_test])\n",
    "        accArr.append(accuracy)\n",
    "        lossArr.append(loss(forest, x[indices_of_test], y[indices_of_test]))\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67c9c6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runKFoldForRF(numberOfFold,x,y,packageForFitness,minLengthRun, m_AC):\n",
    "    accAll, lossAll = [], []\n",
    "    accNeg, lossNeg, percentageNeg = [], [], []\n",
    "    accPos, lossPos, percentagePos = [], [], []\n",
    "    \n",
    "    realFitness, realLBFitness, predictedLBFitness = [], [], []\n",
    "    packageForFitness.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    runtime = []\n",
    "\n",
    "    # use a K-fold Cross-Validation and show average Loss and average Accuracy\n",
    "    kfold = KFold(numberOfFold,)\n",
    "    bestmodel, bestAccuracy = None, 0\n",
    "    \n",
    "    for indices_of_train, indices_of_test in kfold.split(x):\n",
    "        forest = RandomForestClassifier(n_estimators = 100) \n",
    "        forest.fit(x[indices_of_train], y[indices_of_train])\n",
    "        \n",
    "        # compute loss and accuracy on the test items\n",
    "        current_accuracy = accLossPercentage(forest, x, y, indices_of_test, accAll, lossAll, )\n",
    "        \n",
    "        # compute loss and accuracy on the test items that are negatives\n",
    "        accLossPercentage(forest, x, y, indices_of_test, accNeg, lossNeg, percentageNeg,packageForFitness.freqs, 0)\n",
    "\n",
    "        # compute loss and accuracy on the test items that are positives\n",
    "        indices_of_pos = accLossPercentage(forest, x, y, indices_of_test, accPos, lossPos, percentagePos,packageForFitness.freqs, 1) \n",
    "\n",
    "        # compute fitness and lower-bound\n",
    "        realFitness.append(fitness(packageForFitness.iloc[indices_of_test], minLengthRun))\n",
    "        \n",
    "        # compute real LB, which depends on number of pos items\n",
    "        if len(indices_of_pos)>0:\n",
    "            realLBFitness.append(LB_fitness(packageForFitness.iloc[indices_of_test], minLengthRun, m_AC, indices_of_pos))\n",
    "        \n",
    "        # compute predicted LB fitness and runtime\n",
    "        start = time.time()\n",
    "        predictions = forest.predict(x[indices_of_test])\n",
    "        runtime.append((time.time()-start)/len(indices_of_test))\n",
    "        \n",
    "        indices_of_predicted_as_positives = [indices_of_test[i] for i in range(0,len(predictions)) if predictions[i][1]==1]\n",
    "        if len(indices_of_predicted_as_positives)>0:\n",
    "            predictedLBFitness.append(LB_fitness(packageForFitness.iloc[indices_of_test], minLengthRun, m_AC, indices_of_predicted_as_positives))\n",
    "            \n",
    "        if bestAccuracy < current_accuracy:\n",
    "            bestmodel = forest\n",
    "            bestAccuracy = current_accuracy\n",
    "            \n",
    "    print(\"[CROSS-VALIDATION]\\n[ALL] Loss:\", \"{:.3f}\".format(mean(lossAll)), \"\\t Acc:\", \"{:.3f}\".format(mean(accAll)))\n",
    "    print(\"[POSITIVE ({:.2f}%)] Loss:\".format(mean(percentagePos)), \"{:.3f}\".format(mean(lossPos)), \"\\t Acc:\", \"{:.3f}\".format(mean(accPos)))\n",
    "    print(\"[NEGATIVE ({:.2f}%)] Loss:\".format(mean(percentageNeg)), \"{:.3f}\".format(mean(lossNeg)),\"\\t Acc:\", \"{:.3f}\".format(mean(accNeg)))\n",
    "    print(\"Fitness {:.3f}\".format(mean(realFitness)), \"\\t LB Fitness:\", \"{:.3f}\\n\".format(mean(realLBFitness)),\"\\t LB Fitness:\", \"{:.3f}\\n\".format(mean(predictedLBFitness)))\n",
    "    print(\"Runtime (prediction per trace):{:.10f}\".format(mean(runtime)))\n",
    "    return bestmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b47294c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CROSS-VALIDATION]\n",
      "[ALL] Loss: 0.011 \t Acc: 0.997\n",
      "[POSITIVE (1.00%)] Loss: 0.003 \t Acc: 1.000\n",
      "[NEGATIVE (0.00%)] Loss: 1.973 \t Acc: 0.246\n",
      "Fitness 0.950 \t LB Fitness: 0.896\n",
      " \t LB Fitness: 0.898\n",
      "\n",
      "Runtime (prediction per trace):0.0000253525\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of use\n",
    "runKFoldForRF(3,x,y,packageForFitness, minLengthRun, m_AC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44063a2a",
   "metadata": {},
   "source": [
    "# 4. Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1942fcd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " m_AC= 2\n",
      "[CROSS-VALIDATION]\n",
      "[ALL] Loss: 0.037 \t Acc: 0.991\n",
      "[POSITIVE (0.07%)] Loss: 0.118 \t Acc: 0.958\n",
      "[NEGATIVE (0.93%)] Loss: 0.030 \t Acc: 0.993\n",
      "Fitness 0.873 \t LB Fitness: 0.073\n",
      " \t LB Fitness: 0.076\n",
      "\n",
      "Runtime (prediction per trace):0.0000295276\n",
      "(5257,)\n",
      "[TEST]\n",
      "[ALL] Loss: 0.033 \t Acc: 0.990\n",
      "[POSITIVE (0.07%)] Loss: 0.098 \t Acc: 0.962\n",
      "[NEGATIVE (0.93%)] Loss: 0.028 \t Acc: 0.993\n",
      "Fitness 0.874 \t LB Fitness: 0.073\n",
      " \t Predicted LB Fitness: 0.077\n",
      "\n",
      "[MOCK] Loss: 0.032 \t Acc: 0.998\n",
      "-------------------------------------------\n",
      "\n",
      " m_AC= 4\n",
      "[CROSS-VALIDATION]\n",
      "[ALL] Loss: 0.042 \t Acc: 0.982\n",
      "[POSITIVE (0.12%)] Loss: 0.124 \t Acc: 0.935\n",
      "[NEGATIVE (0.88%)] Loss: 0.031 \t Acc: 0.988\n",
      "Fitness 0.873 \t LB Fitness: 0.114\n",
      " \t LB Fitness: 0.116\n",
      "\n",
      "Runtime (prediction per trace):0.0000281858\n",
      "(5257,)\n",
      "[TEST]\n",
      "[ALL] Loss: 0.045 \t Acc: 0.982\n",
      "[POSITIVE (0.12%)] Loss: 0.137 \t Acc: 0.941\n",
      "[NEGATIVE (0.88%)] Loss: 0.032 \t Acc: 0.988\n",
      "Fitness 0.874 \t LB Fitness: 0.115\n",
      " \t Predicted LB Fitness: 0.119\n",
      "\n",
      "[MOCK] Loss: 0.080 \t Acc: 0.982\n",
      "-------------------------------------------\n",
      "\n",
      " m_AC= 6\n",
      "[CROSS-VALIDATION]\n",
      "[ALL] Loss: 0.044 \t Acc: 0.988\n",
      "[POSITIVE (0.18%)] Loss: 0.065 \t Acc: 0.979\n",
      "[NEGATIVE (0.82%)] Loss: 0.039 \t Acc: 0.990\n",
      "Fitness 0.873 \t LB Fitness: 0.171\n",
      " \t LB Fitness: 0.175\n",
      "\n",
      "Runtime (prediction per trace):0.0000315587\n",
      "(5257,)\n",
      "[TEST]\n",
      "[ALL] Loss: 0.037 \t Acc: 0.989\n",
      "[POSITIVE (0.19%)] Loss: 0.068 \t Acc: 0.980\n",
      "[NEGATIVE (0.81%)] Loss: 0.030 \t Acc: 0.992\n",
      "Fitness 0.874 \t LB Fitness: 0.179\n",
      " \t Predicted LB Fitness: 0.182\n",
      "\n",
      "[MOCK] Loss: 0.207 \t Acc: 0.923\n",
      "-------------------------------------------\n",
      "\n",
      " m_AC= 8\n",
      "[CROSS-VALIDATION]\n",
      "[ALL] Loss: 0.079 \t Acc: 0.972\n",
      "[POSITIVE (0.29%)] Loss: 0.089 \t Acc: 0.968\n",
      "[NEGATIVE (0.71%)] Loss: 0.074 \t Acc: 0.973\n",
      "Fitness 0.873 \t LB Fitness: 0.270\n",
      " \t LB Fitness: 0.279\n",
      "\n",
      "Runtime (prediction per trace):0.0000437450\n",
      "(5257,)\n",
      "[TEST]\n",
      "[ALL] Loss: 0.083 \t Acc: 0.968\n",
      "[POSITIVE (0.30%)] Loss: 0.096 \t Acc: 0.964\n",
      "[NEGATIVE (0.70%)] Loss: 0.078 \t Acc: 0.970\n",
      "Fitness 0.874 \t LB Fitness: 0.276\n",
      " \t Predicted LB Fitness: 0.285\n",
      "\n",
      "[MOCK] Loss: 0.297 \t Acc: 0.897\n",
      "-------------------------------------------\n",
      "\n",
      " m_AC= 10\n",
      "[CROSS-VALIDATION]\n",
      "[ALL] Loss: 0.063 \t Acc: 0.980\n",
      "[POSITIVE (0.39%)] Loss: 0.049 \t Acc: 0.981\n",
      "[NEGATIVE (0.61%)] Loss: 0.071 \t Acc: 0.980\n",
      "Fitness 0.873 \t LB Fitness: 0.354\n",
      " \t LB Fitness: 0.358\n",
      "\n",
      "Runtime (prediction per trace):0.0000403424\n",
      "(5257,)\n",
      "[TEST]\n",
      "[ALL] Loss: 0.080 \t Acc: 0.979\n",
      "[POSITIVE (0.40%)] Loss: 0.045 \t Acc: 0.981\n",
      "[NEGATIVE (0.60%)] Loss: 0.103 \t Acc: 0.977\n",
      "Fitness 0.874 \t LB Fitness: 0.358\n",
      " \t Predicted LB Fitness: 0.364\n",
      "\n",
      "[MOCK] Loss: 0.370 \t Acc: 0.848\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "filename = \"A_2017_im.csv\"\n",
    "\n",
    "for i in [2,4,6,8,10]:\n",
    "    print(\"\\n\",\"m_AC=\",i)\n",
    "    \n",
    "    # read the datafile, packageForFitness, minLengthRun, m_AC are needed to compute fitness and LBfitness\n",
    "    x, y, packageForFitness, minLengthRun, m_AC  = cleanDataForRF(\"alignments-\"+filename,i)\n",
    "    \n",
    "    # split the dataset in TRAIN and TEST sets\n",
    "    X_train, X_test, y_train, y_test, packageForFitness_train, packageForFitness_test = train_test_split(x, y, packageForFitness, test_size=0.33, random_state=42)\n",
    "\n",
    "    # ----------------------------------------------\n",
    "    #                     TRAIN \n",
    "    # ----------------------------------------------\n",
    "    # run the cross-validation\n",
    "    bestmodel = runKFoldForRF(10, X_train, y_train, packageForFitness_train, minLengthRun, m_AC)\n",
    "    \n",
    "    # ----------------------------------------------\n",
    "    #                     TEST \n",
    "    # ----------------------------------------------\n",
    "    # use the same function as in the cross-validation but for the test set. \n",
    "    accAll, lossAll = [], []\n",
    "    accNeg, lossNeg, percentageNeg   = [], [], []\n",
    "    accPos, lossPos, percentagePos = [], [], []\n",
    "    \n",
    "    packageForFitness_test.reset_index(drop=True,inplace=True)\n",
    "    print(packageForFitness_test.freqs.shape)\n",
    "    #compute loss and accuracy on the test items \n",
    "    accLossPercentage(bestmodel, X_test, y_test, list(range(0,len(y_test))), accAll, lossAll)\n",
    "        \n",
    "    # compute loss and accuracy on the test items that are negatives\n",
    "    accLossPercentage(bestmodel, X_test, y_test, list(range(0,len(y_test))), accNeg, lossNeg, percentageNeg,packageForFitness_test.freqs, 0)\n",
    "\n",
    "    # compute loss and accuracy on the test items that are positives\n",
    "    indices_of_pos = accLossPercentage(bestmodel, X_test, y_test, list(range(0,len(y_test))), accPos, lossPos, percentagePos,packageForFitness_test.freqs, 1) \n",
    "\n",
    "    # compute fitness and lower-bound\n",
    "    realFitness = fitness(packageForFitness_test, minLengthRun)\n",
    "    if len(indices_of_pos)>0:\n",
    "        realLBFitness = LB_fitness(packageForFitness_test, minLengthRun, m_AC, indices_of_pos)\n",
    "        \n",
    "    # compute predicted LB fitness\n",
    "    predictions = bestmodel.predict(X_test)\n",
    "    indices_of_predicted_as_positives = [i for i in range(0, len(X_test)) if predictions[i][1]==1]\n",
    "    if len(indices_of_predicted_as_positives)>0:\n",
    "        predictedLBFitness = LB_fitness(packageForFitness_test, minLengthRun, m_AC, indices_of_predicted_as_positives)\n",
    "        \n",
    "    print(\"[TEST]\\n[ALL] Loss:\", \"{:.3f}\".format(mean(lossAll)), \"\\t Acc:\", \"{:.3f}\".format(mean(accAll)))\n",
    "    print(\"[POSITIVE ({:.2f}%)] Loss:\".format(mean(percentagePos)), \"{:.3f}\".format(mean(lossPos)), \"\\t Acc:\", \"{:.3f}\".format(mean(accPos)))\n",
    "    print(\"[NEGATIVE ({:.2f}%)] Loss:\".format(mean(percentageNeg)), \"{:.3f}\".format(mean(lossNeg)),\"\\t Acc:\", \"{:.3f}\".format(mean(accNeg)))\n",
    "    print(\"Fitness {:.3f}\".format((realFitness)), \"\\t LB Fitness:\", \"{:.3f}\\n\".format((realLBFitness)),\"\\t Predicted LB Fitness:\", \"{:.3f}\\n\".format((predictedLBFitness)))\n",
    "    \n",
    "    fake_x, fake_y, fake_packageForFitness, fake_minLengthRun, fake_m_AC  = cleanDataForRF(\"alignments-mock-\"+filename,i,vectorizer_already_trained=True)\n",
    "\n",
    "    accFake, lossFake = [], []\n",
    "    accLossPercentage(bestmodel, fake_x, fake_y, range(0,len(fake_y)), accFake, lossFake)\n",
    "    print(\"[MOCK] Loss:\", \"{:.3f}\".format(mean(lossFake)), \"\\t Acc:\", \"{:.3f}\".format(mean(accFake)))\n",
    "    \n",
    "    print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764b98d7",
   "metadata": {},
   "source": [
    "# Bonus: Important Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2841fc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of traces: 15930 \n",
      "Max len of traces: 181\n"
     ]
    }
   ],
   "source": [
    "# ---- (3) prepare the sequences of activities \n",
    "data = pd.read_csv(\"alignments-\"+filename,sep = \";\", \n",
    "                   names = [\"traces\",\"tracesWithMoves\",\"runs\",\"runsWithMoves\",\"costs\",\"frequencies\"])\n",
    "\n",
    "traces_to_matrix = data.traces.str.split(\":::\",expand=True,)\n",
    "number_of_traces, max_len = traces_to_matrix.shape\n",
    "print(\"Number of traces:\", number_of_traces, \"\\nMax len of traces:\", max_len) \n",
    "\n",
    "# transform the matrix to a serie\n",
    "traces_to_serie = pd.concat([traces_to_matrix[i] for i in range(0,max_len)], axis=0, \n",
    "                                      ignore_index=True, sort=False)\n",
    "# from the serie, it's easy to get unique words\n",
    "index_to_word = list(filter(None,(traces_to_serie).unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9701f73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('A_Create Application', 0.0)\n",
      "('A_Submitted', 0.0)\n",
      "('W_Complete application', 0.0)\n",
      "('A_Concept', 0.00010496334607664634)\n",
      "('W_Handle leads', 0.0001918745521716391)\n",
      "('A_Accepted', 0.0019968065082772613)\n",
      "('W_Assess potential fraud', 0.0028161895108348625)\n",
      "('O_Create Offer', 0.003149536613086957)\n",
      "('O_Created', 0.004536081114568189)\n",
      "('W_Shortened completion ', 0.004773947834213605)\n",
      "('O_Sent (online only)', 0.005154637630305176)\n",
      "('O_Sent (mail and online)', 0.005716025153827229)\n",
      "('O_Cancelled', 0.005797008287282642)\n",
      "('A_Cancelled', 0.008843930808015736)\n",
      "('A_Denied', 0.010807772628315105)\n",
      "('O_Refused', 0.018267269867160634)\n",
      "('W_Call after offers', 0.02062744155335336)\n",
      "('A_Complete', 0.022579932326591487)\n",
      "('W_Validate application', 0.03419388784227591)\n",
      "('A_Validating', 0.04055927800916162)\n",
      "('O_Returned', 0.041344253073254)\n",
      "('W_Call incomplete files', 0.04141863408779968)\n",
      "('O_Accepted', 0.041864969568009835)\n",
      "('A_Incomplete', 0.0494769255555316)\n",
      "('A_Pending', 0.07705228005193387)\n",
      "('W_Personal Loan collection', 0.19262486107985932)\n"
     ]
    }
   ],
   "source": [
    "for feature in zip(index_to_word, np.sort(bestmodel.feature_importances_)):\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a48dd65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:IDS22] *",
   "language": "python",
   "name": "conda-env-IDS22-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
