{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a0a2a64",
   "metadata": {},
   "source": [
    "# RNN for An Alignment Cost-Based Classification of Log Traces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab8766c",
   "metadata": {},
   "source": [
    "# 0. Fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40a30c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import time\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "#from keras.layers.embeddings import Embedding\n",
    "from tensorflow.python.keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import Bidirectional\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08dca431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness(packageForFitness, minRunLength):\n",
    "    '''\n",
    "    This function computes the fitness for all the sequences. \n",
    "    @sequences: the sequences of words\n",
    "    @costs: the real alignment cost\n",
    "    @minRunLength: the minimal run in the alignment dataset\n",
    "    '''\n",
    "    sumTraceFitness = 0\n",
    "    totTraces = 0 \n",
    "    for i in packageForFitness.index:\n",
    "        sumTraceFitness += (1 - (packageForFitness.realCosts[i] / ( packageForFitness.lengths[i]  + minRunLength )))#*packageForFitness.freqs[i]\n",
    "        #totTraces += packageForFitness.freqs[i]\n",
    "        totTraces += 1\n",
    "    return sumTraceFitness / totTraces\n",
    "\n",
    "def LB_fitness(packageForFitness, minRunLength, m_AC, indices):\n",
    "    '''\n",
    "    This function computes lower bound of the fitness given in the paper. \n",
    "    @sequences: the sequences of words\n",
    "    @minRunLength: the minimal run in the alignment dataset\n",
    "    @m_AC: needed for the lowerbound formula\n",
    "    @indices: if we compute the lower bound, then we don't iterate on all the traces but only the positives. \n",
    "    '''\n",
    "    sumTraceFitness = 0\n",
    "    totTraces = 0 \n",
    "    for i in indices:\n",
    "        sumTraceFitness += (1 - ((m_AC) / ( packageForFitness.lengths[i] + minRunLength )))#*packageForFitness.freqs[i]\n",
    "    for i in packageForFitness.index:\n",
    "        #totTraces += packageForFitness.freqs[i]\n",
    "        totTraces += 1\n",
    "    return sumTraceFitness / totTraces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209d2a1b",
   "metadata": {},
   "source": [
    "# 1. Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3db5f13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# must be a global variable for fake data\n",
    "word_to_index = {}\n",
    "max_len = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c10199d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanDataForRNN(dataFile,m_AC, word_to_index_already_exists=None):\n",
    "    '''\n",
    "    Reads the file (1), specifies the target classes (2) and prepare the sequences of activities (3). \n",
    "    Finally, its prepare some variables `sequences`, `costs` and `minRunLenght` for computing fitness. \n",
    "    @dataFile: (String) filename of the alignment dataset\n",
    "    @m_AC: (int) maximal alignment cost classifier\n",
    "    '''\n",
    "    # ---- (1) read the file \n",
    "    data = pd.read_csv(dataFile,sep = \";\", \n",
    "                   names = [\"traces\",\"tracesWithMoves\",\"runs\",\"runsWithMoves\",\"costs\",\"frequencies\"])\n",
    "    \n",
    "    # ---- (2) create the positive and negative target depending on the m_AC parameter\n",
    "    # alignment cost which interests us is greater than 10000 (other costs are just silent moves)\n",
    "    # set the fitting to tmp_pos to set them latter to 1\n",
    "    y = (((data[\"costs\"] / 10000).astype(int)) / (m_AC+1)).astype(int)\n",
    "    max_y = y.max()\n",
    "    y = y.replace(0,\"tmp_pos\")\n",
    "    y = y.replace(range(1,max_y + 1), 0)\n",
    "    y = y.replace(\"tmp_pos\",1)\n",
    "\n",
    "    # two columns are required for a binary classification in a RNN\n",
    "    y = np.eye(2)[y.to_numpy().reshape(-1)]\n",
    "    \n",
    "    # ---- (3) prepare the sequences of activities \n",
    "    traces_to_matrix = data.traces.str.split(\":::\",expand=True,)\n",
    "    if word_to_index_already_exists== None:\n",
    "        global max_len\n",
    "        number_of_traces, max_len = traces_to_matrix.shape\n",
    "    \n",
    "    # transform the matrix to a serie\n",
    "    traces_to_serie = pd.concat([traces_to_matrix[i] for i in range(0,traces_to_matrix.shape[1])], axis=0, \n",
    "                                          ignore_index=True, sort=False)\n",
    "    # from the serie, it's easy to get unique words\n",
    "    index_to_word = list(filter(None,(traces_to_serie).unique()))\n",
    "    number_of_activities = len(index_to_word)\n",
    "\n",
    "    # a simple dictionary \n",
    "    if word_to_index_already_exists==None:\n",
    "        global word_to_index \n",
    "        word_to_index = { index_to_word[i]:i+1 for i in range(0, len(index_to_word) ) }\n",
    "    \n",
    "    # loop over traces \n",
    "    x = np.zeros((data.traces.shape[0],max_len))   \n",
    "    for i in range(data.traces.shape[0]):\n",
    "        # Convert the ith training trace and split is into activities. \n",
    "        trace = data.traces[i].split(\":::\")[:-1]\n",
    "        # for every activity name in ith trace, jth is its index /!\\ \n",
    "        j = 0\n",
    "        # Loop over the activities \n",
    "        for w in trace:\n",
    "            # Set the (i,j)th entry of X_trains to the index of the correct word.\n",
    "            x[i, j] = word_to_index[w]\n",
    "            # Increment j to j + 1\n",
    "            j += 1   \n",
    "    \n",
    "    # for fitness computation\n",
    "    minLengthRun= len(data.runs.str.split(\":::\").min())\n",
    "    lengths = data.traces.str.split(\":::\",expand=False,).str.len()-1\n",
    "    realCosts = (data[\"costs\"] / 10000).astype(int)\n",
    "    packageForFitness = pd.DataFrame({\"lengths\":lengths, \"realCosts\": realCosts, \"freqs\": data.frequencies})         \n",
    "    \n",
    "    return x, y, number_of_activities, max_len, index_to_word, packageForFitness, minLengthRun, m_AC   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d29c6152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1., 2., 3., ..., 0., 0., 0.],\n",
       "        [1., 2., 4., ..., 0., 0., 0.],\n",
       "        [1., 2., 4., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 2., 5., ..., 0., 0., 0.],\n",
       "        [1., 2., 5., ..., 0., 0., 0.],\n",
       "        [1., 2., 4., ..., 0., 0., 0.]]),\n",
       " array([[0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        ...,\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of use\n",
    "x, y, number_of_activities, max_len, index_to_word, packageForFitness, minLengthRun, m_AC  = cleanDataForRNN(\"alignments-A_2012_im.csv\",5)\n",
    "x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8446fa",
   "metadata": {},
   "source": [
    "# 2. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67fea3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def myModel(max_len, number_of_activities, verbose=True):\n",
    "    \"\"\"    \n",
    "    Arguments:\n",
    "    input_shape -- shape of the input, usually (max_len,)\n",
    "    size_of_voc -- size of the embedding output\n",
    "    \n",
    "    Returns:\n",
    "    model -- a model instance in Keras\n",
    "    \"\"\"\n",
    "    # Input of the model, type is dtype 'int32' (as it contains indices of activities, which are integers).\n",
    "    indices = Input(shape= (max_len,), dtype='int32')\n",
    "    # Create the embedding layer to reduce to voc size\n",
    "    embeddings = Embedding(input_dim= number_of_activities, output_dim= 15, input_length=max_len)(indices)\n",
    "    # Propagate the embeddings through an Bi-LSTM layer with 50-dimensional hidden state \n",
    "    # Return the batch of sequences (to replay)\n",
    "    X = Bidirectional(LSTM(units = 50, return_sequences=True, go_backwards=True),merge_mode='concat')(embeddings)\n",
    "    # Add dropout with a probability of 0.5 to help with overfitting\n",
    "    X = Dropout(0.5)(X)\n",
    "    # Propagate X trough another LSTM layer with 50-dimensional hidden state\n",
    "    X = LSTM(units = 50, return_sequences=False)(X)\n",
    "    # Add dropout with a probability of 0.5\n",
    "    X = Dropout(0.5)(X)\n",
    "    # Propagate X through a Dense layer of the number of predicting classes\n",
    "    X = Dense(units=2)(X)\n",
    "    # Add a softmax activation\n",
    "    X = Activation('softmax')(X)\n",
    "    \n",
    "    # Create Model instance which converts indices into X.\n",
    "    model = Model(inputs=indices, outputs=X)\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    if verbose:\n",
    "        print(model.summary())\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3e50bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup), but are not present in its tracked objects:   <tf.Variable 'embedding/embeddings:0' shape=(24, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 176)]             0         \n",
      "                                                                 \n",
      " tf.compat.v1.nn.embedding_l  (None, 176, 15)          0         \n",
      " ookup (TFOpLambda)                                              \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 176, 100)         26400     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 176, 100)          0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 50)                30200     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 102       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,702\n",
      "Trainable params: 56,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# example of use\n",
    "model = myModel(max_len, number_of_activities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442a1092",
   "metadata": {},
   "source": [
    "# 3. Cross-Validation of the method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb71fd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accLossPercentageForRNN(model, x, y, indices_of_test, accArr, lossArr, percentageArr=None,  classToTest=None, verbose=2,freqs=None):\n",
    "    '''\n",
    "    This function fills the arrays of results accArr, lossArr and percentageArr for all the test items, or only the \n",
    "    negative items (classToTest=0) or only the positive items (classToTest=1). percentageArr is optional because it \n",
    "    is not required for the entire dataset, i.e., when we do not specify the class. \n",
    "    This works by using a dynamic programmation for the arrays. The return element is either the current accuracy in \n",
    "    case of classToTest=None, either the indices in case of classToTest!=None.\n",
    "    Params:\n",
    "    @forest: a trained model\n",
    "    @x_test: the dataset to test\n",
    "    @y_test: the target value to predict for the test dataset\n",
    "    @accArr: a list of the previous accurary, or an empty list\n",
    "    @lossArr: a list of the previous loss, or an empty list\n",
    "    @percentageArr:  a list of the previous percentage, or an empty list\n",
    "    @classToTest: 1 or 0 for positive and negative. This will find the indices of the items that belongs to the class\n",
    "    '''\n",
    "    if classToTest!=None:\n",
    "        indices = [i for i in indices_of_test if y[i][1]==classToTest]\n",
    "        if len(indices)>0:\n",
    "            loss, acc = model.evaluate(x[indices], y[indices],verbose=verbose)\n",
    "            accArr.append(acc)\n",
    "            lossArr.append(loss)\n",
    "        #percentageArr.append(freqs[indices].sum()/freqs[indices_of_test].sum())\n",
    "        percentageArr.append(len(indices)/len(indices_of_test))\n",
    "        return indices\n",
    "    else :\n",
    "        loss, acc = model.evaluate(x[indices_of_test], y[indices_of_test],verbose=verbose)\n",
    "        accArr.append(acc)\n",
    "        lossArr.append(loss)\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25dcc704",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runKFoldForRNN(numberOfFold, x, y, packageForFitness,minLengthRun, m_AC,\n",
    "                   max_len, number_of_activities, verbose=2,epochs = 10, batch_size = 50):\n",
    "    '''\n",
    "    This function runs a RNN and prints some metrics. \n",
    "    \n",
    "    @model: the created RNN\n",
    "    @numberOfFold: number of fold for the cross validation\n",
    "    @x: sequences\n",
    "    @y: target\n",
    "    '''    \n",
    "    startModel = time.time()\n",
    "    accAll, lossAll = [], []\n",
    "    accNeg, lossNeg, percentageNeg = [], [], []\n",
    "    accPos, lossPos, percentagePos = [], [], []\n",
    "    \n",
    "    realFitness, realLBFitness, predictedLBFitness = [], [], []\n",
    "    packageForFitness.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    runtime = []\n",
    "\n",
    "    # use a K-fold Cross-Validation and show average Loss and average Accuracy\n",
    "    kfold = KFold(numberOfFold)\n",
    "    bestmodel, bestAccuracy = None, 0\n",
    "    \n",
    "    for indices_of_train, indices_of_test in kfold.split(x):\n",
    "        \n",
    "        # train the model\n",
    "        model = myModel(max_len, number_of_activities+1,verbose)\n",
    "        model.fit(x[indices_of_train], y[indices_of_train], verbose=verbose, epochs = 10, batch_size = 50)\n",
    "        \n",
    "        # compute loss and accuracy on the test items\n",
    "        current_accuracy = accLossPercentageForRNN(model, x, y, indices_of_test, accAll, lossAll, verbose=verbose)\n",
    "        \n",
    "        # compute loss and accuracy on the test items that are negatives\n",
    "        accLossPercentageForRNN(model, x, y, indices_of_test, accNeg, lossNeg, percentageNeg, 0, verbose)\n",
    "\n",
    "        # compute loss and accuracy on the test items that are positives\n",
    "        indices_of_pos = accLossPercentageForRNN(model, x, y, indices_of_test, accPos, lossPos, percentagePos, 1, verbose) \n",
    "\n",
    "        # compute fitness and lower-bound\n",
    "        realFitness.append(fitness(packageForFitness.iloc[indices_of_test], minLengthRun))\n",
    "        if len(indices_of_pos)>0:\n",
    "            realLBFitness.append(LB_fitness(packageForFitness.iloc[indices_of_test], minLengthRun, m_AC, indices_of_pos))\n",
    "        \n",
    "        # compute predicted LB fitness and runtime\n",
    "        start = time.time()\n",
    "        predictions = model.predict(x[indices_of_test])\n",
    "        runtime.append((time.time()-start)/len(indices_of_test))\n",
    "        indices_of_predicted_as_positives = [indices_of_test[i] for i in range(0,len(predictions)) if predictions[i][1]>=0.5]\n",
    "        if len(indices_of_predicted_as_positives)>0:\n",
    "            predictedLBFitness.append(LB_fitness(packageForFitness.iloc[indices_of_test], minLengthRun, m_AC, indices_of_predicted_as_positives))\n",
    "\n",
    "        if bestAccuracy < current_accuracy:\n",
    "            bestmodel = model\n",
    "            bestAccuracy = current_accuracy\n",
    "    print(\"TIME:\",time.time()-startModel)   \n",
    "    print(\"[CROSS-VALIDATION]\\n[ALL] Loss:\", \"{:.3f}\".format(mean(lossAll)), \"\\t Acc:\", \"{:.3f}\".format(mean(accAll)))\n",
    "    print(\"[POSITIVE ({:.2f}%)] Loss:\".format(mean(percentagePos)), \"{:.3f}\".format(mean(lossPos)), \"\\t Acc:\", \"{:.3f}\".format(mean(accPos)))\n",
    "    print(\"[NEGATIVE ({:.2f}%)] Loss:\".format(mean(percentageNeg)), \"{:.3f}\".format(mean(lossNeg)),\"\\t Acc:\", \"{:.3f}\".format(mean(accNeg)))\n",
    "    print(\"Fitness {:.3f}\".format(mean(realFitness)), \"\\t LB Fitness:\", \"{:.3f}\\n\".format(mean(realLBFitness)),\"\\t Predicted LB Fitness:\", \"{:.3f}\\n\".format(mean(predictedLBFitness)))\n",
    "    print(\"Runtime (prediction per trace):{:.10f}\".format(mean(runtime)))\n",
    "    return bestmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff327cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_1), but are not present in its tracked objects:   <tf.Variable 'embedding_1/embeddings:0' shape=(25, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 176)]             0         \n",
      "                                                                 \n",
      " tf.compat.v1.nn.embedding_l  (None, 176, 15)          0         \n",
      " ookup_1 (TFOpLambda)                                            \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 176, 100)         26400     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 176, 100)          0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 50)                30200     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 102       \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,702\n",
      "Trainable params: 56,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "59/59 - 17s - loss: 0.1683 - accuracy: 0.9828 - 17s/epoch - 296ms/step\n",
      "Epoch 2/10\n",
      "59/59 - 10s - loss: 0.0094 - accuracy: 0.9993 - 10s/epoch - 171ms/step\n",
      "Epoch 3/10\n",
      "59/59 - 13s - loss: 0.0071 - accuracy: 0.9993 - 13s/epoch - 228ms/step\n",
      "Epoch 4/10\n",
      "59/59 - 13s - loss: 0.0068 - accuracy: 0.9993 - 13s/epoch - 222ms/step\n",
      "Epoch 5/10\n",
      "59/59 - 13s - loss: 0.0072 - accuracy: 0.9993 - 13s/epoch - 224ms/step\n",
      "Epoch 6/10\n",
      "59/59 - 15s - loss: 0.0068 - accuracy: 0.9993 - 15s/epoch - 248ms/step\n",
      "Epoch 7/10\n",
      "59/59 - 17s - loss: 0.0061 - accuracy: 0.9993 - 17s/epoch - 281ms/step\n",
      "Epoch 8/10\n",
      "59/59 - 18s - loss: 0.0072 - accuracy: 0.9993 - 18s/epoch - 304ms/step\n",
      "Epoch 9/10\n",
      "59/59 - 17s - loss: 0.0062 - accuracy: 0.9993 - 17s/epoch - 288ms/step\n",
      "Epoch 10/10\n",
      "59/59 - 15s - loss: 0.0061 - accuracy: 0.9993 - 15s/epoch - 252ms/step\n",
      "46/46 - 7s - loss: 0.0059 - accuracy: 0.9993 - 7s/epoch - 142ms/step\n",
      "1/1 - 0s - loss: 8.1617 - accuracy: 0.0000e+00 - 107ms/epoch - 107ms/step\n",
      "46/46 - 3s - loss: 2.8542e-04 - accuracy: 1.0000 - 3s/epoch - 69ms/step\n",
      "46/46 [==============================] - 5s 61ms/step\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_2), but are not present in its tracked objects:   <tf.Variable 'embedding_2/embeddings:0' shape=(25, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 176)]             0         \n",
      "                                                                 \n",
      " tf.compat.v1.nn.embedding_l  (None, 176, 15)          0         \n",
      " ookup_2 (TFOpLambda)                                            \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 176, 100)         26400     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 176, 100)          0         \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 50)                30200     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 102       \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,702\n",
      "Trainable params: 56,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "59/59 - 24s - loss: 0.1581 - accuracy: 0.9825 - 24s/epoch - 411ms/step\n",
      "Epoch 2/10\n",
      "59/59 - 15s - loss: 0.0086 - accuracy: 0.9993 - 15s/epoch - 249ms/step\n",
      "Epoch 3/10\n",
      "59/59 - 14s - loss: 0.0078 - accuracy: 0.9993 - 14s/epoch - 245ms/step\n",
      "Epoch 4/10\n",
      "59/59 - 14s - loss: 0.0076 - accuracy: 0.9993 - 14s/epoch - 232ms/step\n",
      "Epoch 5/10\n",
      "59/59 - 14s - loss: 0.0068 - accuracy: 0.9993 - 14s/epoch - 240ms/step\n",
      "Epoch 6/10\n",
      "59/59 - 15s - loss: 0.0068 - accuracy: 0.9993 - 15s/epoch - 247ms/step\n",
      "Epoch 7/10\n",
      "59/59 - 13s - loss: 0.0066 - accuracy: 0.9993 - 13s/epoch - 228ms/step\n",
      "Epoch 8/10\n",
      "59/59 - 14s - loss: 0.0055 - accuracy: 0.9993 - 14s/epoch - 243ms/step\n",
      "Epoch 9/10\n",
      "59/59 - 14s - loss: 0.0063 - accuracy: 0.9993 - 14s/epoch - 243ms/step\n",
      "Epoch 10/10\n",
      "59/59 - 15s - loss: 0.0069 - accuracy: 0.9993 - 15s/epoch - 251ms/step\n",
      "46/46 - 4s - loss: 0.0059 - accuracy: 0.9993 - 4s/epoch - 91ms/step\n",
      "1/1 - 0s - loss: 8.1116 - accuracy: 0.0000e+00 - 83ms/epoch - 83ms/step\n",
      "46/46 - 3s - loss: 3.0047e-04 - accuracy: 1.0000 - 3s/epoch - 59ms/step\n",
      "46/46 [==============================] - 4s 51ms/step\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_3), but are not present in its tracked objects:   <tf.Variable 'embedding_3/embeddings:0' shape=(25, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 176)]             0         \n",
      "                                                                 \n",
      " tf.compat.v1.nn.embedding_l  (None, 176, 15)          0         \n",
      " ookup_3 (TFOpLambda)                                            \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, 176, 100)         26400     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 176, 100)          0         \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 50)                30200     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 102       \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 2)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 56,702\n",
      "Trainable params: 56,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "59/59 - 20s - loss: 0.1536 - accuracy: 0.9911 - 20s/epoch - 338ms/step\n",
      "Epoch 2/10\n",
      "59/59 - 15s - loss: 0.0078 - accuracy: 0.9993 - 15s/epoch - 250ms/step\n",
      "Epoch 3/10\n",
      "59/59 - 15s - loss: 0.0068 - accuracy: 0.9993 - 15s/epoch - 247ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "59/59 - 13s - loss: 0.0073 - accuracy: 0.9993 - 13s/epoch - 226ms/step\n",
      "Epoch 5/10\n",
      "59/59 - 13s - loss: 0.0074 - accuracy: 0.9993 - 13s/epoch - 226ms/step\n",
      "Epoch 6/10\n",
      "59/59 - 14s - loss: 0.0067 - accuracy: 0.9993 - 14s/epoch - 244ms/step\n",
      "Epoch 7/10\n",
      "59/59 - 14s - loss: 0.0068 - accuracy: 0.9993 - 14s/epoch - 242ms/step\n",
      "Epoch 8/10\n",
      "59/59 - 16s - loss: 0.0069 - accuracy: 0.9993 - 16s/epoch - 273ms/step\n",
      "Epoch 9/10\n",
      "59/59 - 15s - loss: 0.0058 - accuracy: 0.9993 - 15s/epoch - 261ms/step\n",
      "Epoch 10/10\n",
      "59/59 - 15s - loss: 0.0059 - accuracy: 0.9993 - 15s/epoch - 248ms/step\n",
      "46/46 - 6s - loss: 0.0058 - accuracy: 0.9993 - 6s/epoch - 120ms/step\n",
      "1/1 - 0s - loss: 8.0340 - accuracy: 0.0000e+00 - 43ms/epoch - 43ms/step\n",
      "46/46 - 3s - loss: 3.2493e-04 - accuracy: 1.0000 - 3s/epoch - 56ms/step\n",
      "46/46 [==============================] - 5s 64ms/step\n",
      "TIME: 497.9206864833832\n",
      "[CROSS-VALIDATION]\n",
      "[ALL] Loss: 0.006 \t Acc: 0.999\n",
      "[POSITIVE (1.00%)] Loss: 0.000 \t Acc: 1.000\n",
      "[NEGATIVE (0.00%)] Loss: 8.102 \t Acc: 0.000\n",
      "Fitness 0.950 \t LB Fitness: 0.874\n",
      " \t Predicted LB Fitness: 0.875\n",
      "\n",
      "Runtime (prediction per trace):0.0034437500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x28b431709a0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of use\n",
    "runKFoldForRNN(3,x,y, packageForFitness,minLengthRun, m_AC,max_len, number_of_activities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793c1567",
   "metadata": {},
   "source": [
    "# 4. Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "843c53c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " m_AC= 2\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_4), but are not present in its tracked objects:   <tf.Variable 'embedding_4/embeddings:0' shape=(27, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "34/34 [==============================] - 4s 55ms/step\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_5), but are not present in its tracked objects:   <tf.Variable 'embedding_5/embeddings:0' shape=(27, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "34/34 [==============================] - 4s 46ms/step\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_6), but are not present in its tracked objects:   <tf.Variable 'embedding_6/embeddings:0' shape=(27, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "34/34 [==============================] - 3s 44ms/step\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_7), but are not present in its tracked objects:   <tf.Variable 'embedding_7/embeddings:0' shape=(27, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "34/34 [==============================] - 3s 57ms/step\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_8), but are not present in its tracked objects:   <tf.Variable 'embedding_8/embeddings:0' shape=(27, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "34/34 [==============================] - 2s 41ms/step\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_9), but are not present in its tracked objects:   <tf.Variable 'embedding_9/embeddings:0' shape=(27, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "34/34 [==============================] - 3s 55ms/step\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_10), but are not present in its tracked objects:   <tf.Variable 'embedding_10/embeddings:0' shape=(27, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "34/34 [==============================] - 4s 69ms/step\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_11), but are not present in its tracked objects:   <tf.Variable 'embedding_11/embeddings:0' shape=(27, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "34/34 [==============================] - 3s 64ms/step\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_12), but are not present in its tracked objects:   <tf.Variable 'embedding_12/embeddings:0' shape=(27, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "34/34 [==============================] - 3s 69ms/step\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_13), but are not present in its tracked objects:   <tf.Variable 'embedding_13/embeddings:0' shape=(27, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "34/34 [==============================] - 4s 73ms/step\n",
      "TIME: 5054.241726875305\n",
      "[CROSS-VALIDATION]\n",
      "[ALL] Loss: 0.255 \t Acc: 0.932\n",
      "[POSITIVE (0.07%)] Loss: 2.634 \t Acc: 0.100\n",
      "[NEGATIVE (0.93%)] Loss: 0.074 \t Acc: 0.998\n",
      "Fitness 0.873 \t LB Fitness: 0.073\n",
      " \t Predicted LB Fitness: 0.092\n",
      "\n",
      "Runtime (prediction per trace):0.0032249906\n",
      "165/165 [==============================] - 13s 81ms/step\n",
      "[TEST]\n",
      "[ALL] Loss: 0.042 \t Acc: 0.984\n",
      "[POSITIVE (0.07%)] Loss: 0.210 \t Acc: 0.972\n",
      "[NEGATIVE (0.93%)] Loss: 0.029 \t Acc: 0.985\n",
      "Fitness 0.874 \t LB Fitness: 0.073\n",
      " \t Predicted LB Fitness: 0.085\n",
      "\n",
      "32/32 - 1s - loss: 0.0676 - accuracy: 0.9600 - 1s/epoch - 46ms/step\n",
      "[MOCK] Loss: 0.068 \t Acc: 0.960\n",
      "-------------------------------------------\n",
      "\n",
      " m_AC= 4\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_14), but are not present in its tracked objects:   <tf.Variable 'embedding_14/embeddings:0' shape=(27, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "34/34 [==============================] - 3s 65ms/step\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_15), but are not present in its tracked objects:   <tf.Variable 'embedding_15/embeddings:0' shape=(27, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "34/34 [==============================] - 3s 48ms/step\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_16), but are not present in its tracked objects:   <tf.Variable 'embedding_16/embeddings:0' shape=(27, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "34/34 [==============================] - 3s 44ms/step\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_17), but are not present in its tracked objects:   <tf.Variable 'embedding_17/embeddings:0' shape=(27, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "34/34 [==============================] - 3s 53ms/step\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_18), but are not present in its tracked objects:   <tf.Variable 'embedding_18/embeddings:0' shape=(27, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "34/34 [==============================] - 4s 60ms/step\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_19), but are not present in its tracked objects:   <tf.Variable 'embedding_19/embeddings:0' shape=(27, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "34/34 [==============================] - 3s 54ms/step\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_20), but are not present in its tracked objects:   <tf.Variable 'embedding_20/embeddings:0' shape=(27, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "34/34 [==============================] - 4s 59ms/step\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_21), but are not present in its tracked objects:   <tf.Variable 'embedding_21/embeddings:0' shape=(27, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "34/34 [==============================] - 3s 55ms/step\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_22), but are not present in its tracked objects:   <tf.Variable 'embedding_22/embeddings:0' shape=(27, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "34/34 [==============================] - 3s 56ms/step\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_23), but are not present in its tracked objects:   <tf.Variable 'embedding_23/embeddings:0' shape=(27, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 3s 61ms/step\n",
      "TIME: 4625.849546670914\n",
      "[CROSS-VALIDATION]\n",
      "[ALL] Loss: 0.288 \t Acc: 0.897\n",
      "[POSITIVE (0.12%)] Loss: 1.707 \t Acc: 0.174\n",
      "[NEGATIVE (0.88%)] Loss: 0.094 \t Acc: 0.996\n",
      "Fitness 0.873 \t LB Fitness: 0.114\n",
      " \t Predicted LB Fitness: 0.075\n",
      "\n",
      "Runtime (prediction per trace):0.0030364123\n",
      "165/165 [==============================] - 10s 58ms/step\n",
      "[TEST]\n",
      "[ALL] Loss: 0.064 \t Acc: 0.973\n",
      "[POSITIVE (0.12%)] Loss: 0.172 \t Acc: 0.926\n",
      "[NEGATIVE (0.88%)] Loss: 0.049 \t Acc: 0.980\n",
      "Fitness 0.874 \t LB Fitness: 0.115\n",
      " \t Predicted LB Fitness: 0.124\n",
      "\n",
      "32/32 - 2s - loss: 0.2797 - accuracy: 0.8959 - 2s/epoch - 56ms/step\n",
      "[MOCK] Loss: 0.280 \t Acc: 0.896\n",
      "-------------------------------------------\n",
      "\n",
      " m_AC= 6\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_24), but are not present in its tracked objects:   <tf.Variable 'embedding_24/embeddings:0' shape=(27, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "34/34 [==============================] - 3s 53ms/step\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_25), but are not present in its tracked objects:   <tf.Variable 'embedding_25/embeddings:0' shape=(27, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "34/34 [==============================] - 3s 56ms/step\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_26), but are not present in its tracked objects:   <tf.Variable 'embedding_26/embeddings:0' shape=(27, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "34/34 [==============================] - 3s 52ms/step\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_27), but are not present in its tracked objects:   <tf.Variable 'embedding_27/embeddings:0' shape=(27, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "34/34 [==============================] - 3s 53ms/step\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_28), but are not present in its tracked objects:   <tf.Variable 'embedding_28/embeddings:0' shape=(27, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "34/34 [==============================] - 3s 54ms/step\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_29), but are not present in its tracked objects:   <tf.Variable 'embedding_29/embeddings:0' shape=(27, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "34/34 [==============================] - 4s 61ms/step\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_30), but are not present in its tracked objects:   <tf.Variable 'embedding_30/embeddings:0' shape=(27, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "34/34 [==============================] - 4s 56ms/step\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_31), but are not present in its tracked objects:   <tf.Variable 'embedding_31/embeddings:0' shape=(27, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "34/34 [==============================] - 3s 55ms/step\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_32), but are not present in its tracked objects:   <tf.Variable 'embedding_32/embeddings:0' shape=(27, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "34/34 [==============================] - 3s 57ms/step\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_33), but are not present in its tracked objects:   <tf.Variable 'embedding_33/embeddings:0' shape=(27, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "34/34 [==============================] - 4s 60ms/step\n",
      "TIME: 4763.572948217392\n",
      "[CROSS-VALIDATION]\n",
      "[ALL] Loss: 0.205 \t Acc: 0.920\n",
      "[POSITIVE (0.18%)] Loss: 0.710 \t Acc: 0.621\n",
      "[NEGATIVE (0.82%)] Loss: 0.091 \t Acc: 0.988\n",
      "Fitness 0.873 \t LB Fitness: 0.171\n",
      " \t Predicted LB Fitness: 0.164\n",
      "\n",
      "Runtime (prediction per trace):0.0031982519\n",
      "165/165 [==============================] - 10s 61ms/step\n",
      "[TEST]\n",
      "[ALL] Loss: 0.045 \t Acc: 0.983\n",
      "[POSITIVE (0.19%)] Loss: 0.118 \t Acc: 0.961\n",
      "[NEGATIVE (0.81%)] Loss: 0.028 \t Acc: 0.989\n",
      "Fitness 0.874 \t LB Fitness: 0.179\n",
      " \t Predicted LB Fitness: 0.180\n",
      "\n",
      "32/32 - 2s - loss: 0.3736 - accuracy: 0.9069 - 2s/epoch - 58ms/step\n",
      "[MOCK] Loss: 0.374 \t Acc: 0.907\n",
      "-------------------------------------------\n",
      "\n",
      " m_AC= 8\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_34), but are not present in its tracked objects:   <tf.Variable 'embedding_34/embeddings:0' shape=(27, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "34/34 [==============================] - 4s 89ms/step\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_35), but are not present in its tracked objects:   <tf.Variable 'embedding_35/embeddings:0' shape=(27, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "34/34 [==============================] - 4s 85ms/step\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_36), but are not present in its tracked objects:   <tf.Variable 'embedding_36/embeddings:0' shape=(27, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "34/34 [==============================] - 4s 80ms/step\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_37), but are not present in its tracked objects:   <tf.Variable 'embedding_37/embeddings:0' shape=(27, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "34/34 [==============================] - 4s 83ms/step\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_38), but are not present in its tracked objects:   <tf.Variable 'embedding_38/embeddings:0' shape=(27, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "34/34 [==============================] - 4s 88ms/step\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_39), but are not present in its tracked objects:   <tf.Variable 'embedding_39/embeddings:0' shape=(27, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "34/34 [==============================] - 5s 97ms/step\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_40), but are not present in its tracked objects:   <tf.Variable 'embedding_40/embeddings:0' shape=(27, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "34/34 [==============================] - 4s 93ms/step\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_41), but are not present in its tracked objects:   <tf.Variable 'embedding_41/embeddings:0' shape=(27, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 4s 76ms/step\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_42), but are not present in its tracked objects:   <tf.Variable 'embedding_42/embeddings:0' shape=(27, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "34/34 [==============================] - 4s 79ms/step\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_43), but are not present in its tracked objects:   <tf.Variable 'embedding_43/embeddings:0' shape=(27, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "34/34 [==============================] - 4s 80ms/step\n",
      "TIME: 6270.219386577606\n",
      "[CROSS-VALIDATION]\n",
      "[ALL] Loss: 0.166 \t Acc: 0.927\n",
      "[POSITIVE (0.29%)] Loss: 0.256 \t Acc: 0.856\n",
      "[NEGATIVE (0.71%)] Loss: 0.129 \t Acc: 0.955\n",
      "Fitness 0.873 \t LB Fitness: 0.270\n",
      " \t Predicted LB Fitness: 0.291\n",
      "\n",
      "Runtime (prediction per trace):0.0038394067\n",
      "165/165 [==============================] - 13s 80ms/step\n",
      "[TEST]\n",
      "[ALL] Loss: 0.101 \t Acc: 0.958\n",
      "[POSITIVE (0.30%)] Loss: 0.162 \t Acc: 0.944\n",
      "[NEGATIVE (0.70%)] Loss: 0.074 \t Acc: 0.964\n",
      "Fitness 0.874 \t LB Fitness: 0.276\n",
      " \t Predicted LB Fitness: 0.284\n",
      "\n",
      "32/32 - 2s - loss: 0.2913 - accuracy: 0.9179 - 2s/epoch - 76ms/step\n",
      "[MOCK] Loss: 0.291 \t Acc: 0.918\n",
      "-------------------------------------------\n",
      "\n",
      " m_AC= 10\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_44), but are not present in its tracked objects:   <tf.Variable 'embedding_44/embeddings:0' shape=(27, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "34/34 [==============================] - 6s 130ms/step\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_45), but are not present in its tracked objects:   <tf.Variable 'embedding_45/embeddings:0' shape=(27, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "34/34 [==============================] - 4s 92ms/step\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_46), but are not present in its tracked objects:   <tf.Variable 'embedding_46/embeddings:0' shape=(27, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "34/34 [==============================] - 4s 95ms/step\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_47), but are not present in its tracked objects:   <tf.Variable 'embedding_47/embeddings:0' shape=(27, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "34/34 [==============================] - 7s 170ms/step\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_48), but are not present in its tracked objects:   <tf.Variable 'embedding_48/embeddings:0' shape=(27, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "34/34 [==============================] - 8s 177ms/step\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_49), but are not present in its tracked objects:   <tf.Variable 'embedding_49/embeddings:0' shape=(27, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "34/34 [==============================] - 7s 151ms/step\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_50), but are not present in its tracked objects:   <tf.Variable 'embedding_50/embeddings:0' shape=(27, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "34/34 [==============================] - 7s 171ms/step\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_51), but are not present in its tracked objects:   <tf.Variable 'embedding_51/embeddings:0' shape=(27, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "34/34 [==============================] - 6s 158ms/step\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_52), but are not present in its tracked objects:   <tf.Variable 'embedding_52/embeddings:0' shape=(27, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "34/34 [==============================] - 6s 149ms/step\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_53), but are not present in its tracked objects:   <tf.Variable 'embedding_53/embeddings:0' shape=(27, 15) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "34/34 [==============================] - 6s 158ms/step\n",
      "TIME: 9890.342503070831\n",
      "[CROSS-VALIDATION]\n",
      "[ALL] Loss: 0.225 \t Acc: 0.885\n",
      "[POSITIVE (0.39%)] Loss: 0.283 \t Acc: 0.765\n",
      "[NEGATIVE (0.61%)] Loss: 0.190 \t Acc: 0.961\n",
      "Fitness 0.873 \t LB Fitness: 0.354\n",
      " \t Predicted LB Fitness: 0.366\n",
      "\n",
      "Runtime (prediction per trace):0.0059152922\n",
      "165/165 [==============================] - 28s 168ms/step\n",
      "[TEST]\n",
      "[ALL] Loss: 0.085 \t Acc: 0.971\n",
      "[POSITIVE (0.40%)] Loss: 0.078 \t Acc: 0.973\n",
      "[NEGATIVE (0.60%)] Loss: 0.090 \t Acc: 0.970\n",
      "Fitness 0.874 \t LB Fitness: 0.358\n",
      " \t Predicted LB Fitness: 0.365\n",
      "\n",
      "32/32 - 6s - loss: 0.7043 - accuracy: 0.8539 - 6s/epoch - 179ms/step\n",
      "[MOCK] Loss: 0.704 \t Acc: 0.854\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "filename = \"A_2017_im.csv\"\n",
    "\n",
    "for i in [2,4,6,8,10]:\n",
    "    print(\"\\n\",\"m_AC=\",i)\n",
    "    \n",
    "    # read the datafile, packageForFitness, minLengthRun, m_AC are needed to compute fitness and LBfitness\n",
    "    x, y, number_of_activities, max_len, index_to_word, packageForFitness, minLengthRun, m_AC  = cleanDataForRNN(\"alignments-\"+filename,i)\n",
    "    \n",
    "    # split the dataset in TRAIN and TEST sets\n",
    "    X_train, X_test, y_train, y_test, packageForFitness_train, packageForFitness_test = train_test_split(x, y, packageForFitness, test_size=0.33, random_state=42)\n",
    "\n",
    "    # ----------------------------------------------\n",
    "    #                     TRAIN \n",
    "    # ----------------------------------------------\n",
    "    # run the cross-validation\n",
    "    bestmodel = runKFoldForRNN(10, X_train, y_train, packageForFitness_train, minLengthRun, m_AC, max_len, number_of_activities, verbose=0)\n",
    "\n",
    "    # ----------------------------------------------\n",
    "    #                     TEST \n",
    "    # ----------------------------------------------\n",
    "    # use the same function as in the cross-validation but for the test set. \n",
    "    accAll, lossAll = [], []\n",
    "    accNeg, lossNeg, percentageNeg = [], [], []\n",
    "    accPos, lossPos, percentagePos = [], [], []\n",
    "    \n",
    "    packageForFitness_test.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    #compute loss and accuracy on the test items \n",
    "    accLossPercentageForRNN(bestmodel, X_test, y_test, range(0,len(y_test)), accAll, lossAll, verbose=0)\n",
    "        \n",
    "    # compute loss and accuracy on the test items that are negatives\n",
    "    accLossPercentageForRNN(bestmodel, X_test, y_test, range(0,len(y_test)), accNeg, lossNeg, percentageNeg, 0, 0)\n",
    "\n",
    "    # compute loss and accuracy on the test items that are positives\n",
    "    indices_of_pos = accLossPercentageForRNN(bestmodel, X_test, y_test, range(0,len(y_test)), accPos, lossPos,percentagePos,  1, 0) \n",
    "\n",
    "    # compute fitness and lower-bound\n",
    "    realFitness = fitness(packageForFitness_test, minLengthRun)\n",
    "    if len(indices_of_pos)>0:\n",
    "        LBFitness = LB_fitness(packageForFitness_test, minLengthRun, m_AC, indices_of_pos)\n",
    "        \n",
    "    # compute predicted LB fitness\n",
    "    predictions = bestmodel.predict(X_test)\n",
    "    indices_of_predicted_as_positives = [i for i in range(0, len(X_test)) if predictions[i][1]>=0.5]\n",
    "    if len(indices_of_predicted_as_positives)>0:\n",
    "        predictedLBFitness = LB_fitness(packageForFitness_test, minLengthRun, m_AC, indices_of_predicted_as_positives)\n",
    "        \n",
    "    print(\"[TEST]\\n[ALL] Loss:\", \"{:.3f}\".format(mean(lossAll)), \"\\t Acc:\", \"{:.3f}\".format(mean(accAll)))\n",
    "    print(\"[POSITIVE ({:.2f}%)] Loss:\".format(mean(percentagePos)), \"{:.3f}\".format(mean(lossPos)), \"\\t Acc:\", \"{:.3f}\".format(mean(accPos)))\n",
    "    print(\"[NEGATIVE ({:.2f}%)] Loss:\".format(mean(percentageNeg)), \"{:.3f}\".format(mean(lossNeg)),\"\\t Acc:\", \"{:.3f}\".format(mean(accNeg)))\n",
    "    print(\"Fitness {:.3f}\".format((realFitness)), \"\\t LB Fitness:\", \"{:.3f}\\n\".format((LBFitness)),\"\\t Predicted LB Fitness:\", \"{:.3f}\\n\".format((predictedLBFitness)) )\n",
    "\n",
    "    fake_x, fake_y, fake_number_of_activities, fake_max_len, fake_index_to_word, fake_packageForFitness, fake_minLengthRun, fake_m_AC  = cleanDataForRNN(\"alignments-mock-\"+filename,2,word_to_index_already_exists=True)\n",
    "    accFake, lossFake = [], []\n",
    "    accLossPercentageForRNN(bestmodel, fake_x, fake_y, range(0,len(fake_y)), accFake, lossFake)\n",
    "    print(\"[MOCK] Loss:\", \"{:.3f}\".format(mean(lossFake)), \"\\t Acc:\", \"{:.3f}\".format(mean(accFake)))\n",
    "    print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74ea9d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:IDS22] *",
   "language": "python",
   "name": "conda-env-IDS22-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
